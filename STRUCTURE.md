# ğŸ“ Project Structure

```
ğŸ“¦ data_pipeline/
â”œâ”€â”€ ğŸ“ airflow/                 # Apache Airflow configurations
â”‚   â”œâ”€â”€ ğŸ“ dags/               # DAG definitions
â”‚   â”œâ”€â”€ ğŸ“ logs/               # Airflow logs (gitignored)
â”‚   â””â”€â”€ ğŸ“ plugins/            # Custom Airflow plugins
â”œâ”€â”€ ğŸ“ config/                 # Configuration files
â”‚   â””â”€â”€ ğŸ“ grafana/           # Grafana datasources config
â”œâ”€â”€ ğŸ“ data/                   # ğŸ†• CSV data files
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”œâ”€â”€ olist_order_payments_dataset.csv
â”‚   â”œâ”€â”€ olist_order_reviews_dataset.csv
â”‚   â”œâ”€â”€ olist_products_dataset.csv
â”‚   â”œâ”€â”€ olist_sellers_dataset.csv
â”‚   â”œâ”€â”€ olist_geolocation_dataset.csv
â”‚   â””â”€â”€ product_category_name_translation.csv
â”œâ”€â”€ ğŸ“ dbt_project/            # dbt transformations
â”‚   â”œâ”€â”€ ğŸ“ models/            # dbt models
â”‚   â”‚   â”œâ”€â”€ ğŸ“ sources/       # Source definitions
â”‚   â”‚   â”œâ”€â”€ ğŸ“ staging/       # Staging models
â”‚   â”‚   â””â”€â”€ ğŸ“ marts/         # Business marts
â”‚   â”œâ”€â”€ dbt_project.yml       # dbt project config
â”‚   â”œâ”€â”€ profiles.yml          # dbt connection profiles
â”‚   â””â”€â”€ packages.yml          # ğŸ†• dbt package dependencies
â”œâ”€â”€ ğŸ“ great_expectations/     # Data quality tests
â”œâ”€â”€ ğŸ“ init/                   # Database initialization scripts
â”œâ”€â”€ ğŸ“ spark/                  # Apache Spark jobs
â”‚   â””â”€â”€ data_processor.py     # Main data processing script
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Docker services definition
â”œâ”€â”€ ğŸ“„ Dockerfile.airflow      # ğŸ†• Custom Airflow image with dbt
â”œâ”€â”€ ğŸ“„ Makefile               # Project commands
â”œâ”€â”€ ğŸ“„ README.md              # Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.sh              # Setup script
â””â”€â”€ ğŸ“„ .gitignore            # ğŸ†• Git ignore rules
```

## ğŸ—‘ï¸ Files Removed During Cleanup

### âŒ Removed Files:
- `simple_data_loader.py` - Temporary data loading script
- `data_pipeline/` - Duplicate directory structure
- `dbt_project/target/` - Generated dbt files
- `dbt_project/logs/` - dbt log files
- `dbt_project/.user.yml` - User-specific dbt config
- `airflow/dags/__pycache__/` - Python cache files

### ğŸ“ New Files:
- `.gitignore` - Git ignore rules for generated files
- `STRUCTURE.md` - This documentation

## ğŸ”§ Path Updates Made:
- Data files moved to `/data/` directory
- Docker volume mounts updated to use `./data/` instead of `../`
- Spark data processor path updated to `/opt/airflow/data`

## ğŸ¯ Benefits of Cleanup:
- âœ… Cleaner project structure
- âœ… No duplicate files or directories  
- âœ… Proper gitignore to avoid committing generated files
- âœ… Organized data files in dedicated directory
- âœ… Consistent path mappings across services
